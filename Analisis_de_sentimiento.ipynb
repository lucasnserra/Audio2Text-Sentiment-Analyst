{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2DRFmst1cMfNjpbeS083d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucasnserra/Audio2Text-Sentiment-Analyst/blob/main/Analisis_de_sentimiento.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Esta Notebook utiliza 2 modelos preentrenados de Hugging Face basados en transformers que te permitiran pasar audios a texto y tambien analizar la probabilidad que ese texto sea Positivo, negativo o neutro.\n"
      ],
      "metadata": {
        "id": "MJv3WkXUdEPT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eFpgfdudDf-"
      },
      "outputs": [],
      "source": [
        "#instalamos librerias necesarias \n",
        "!pip install transformers \n",
        "!pip install pysentimiento\n",
        "!pip install soundfile\n",
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importamos librerias que consideramos necesarias para nuestro analisis\n",
        "\n",
        "#librerias basicas\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "\n",
        "#importamos librerias de analisis de sentimiento\n",
        "from pysentimiento import create_analyzer #analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
        "\n",
        "#Libreria de procesamiento de audio a texto \n",
        "from transformers import AutoProcessor, AutoModelForSpeechSeq2Seq\n",
        "import torch\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "\n"
      ],
      "metadata": {
        "id": "yUFUagLadcvg"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcion de analisis de sentimiento\n",
        "def prediccion_texto(texto):\n",
        "    analyzer = create_analyzer(task=\"sentiment\", lang=\"es\")\n",
        "    resultado = analyzer.predict(texto)\n",
        "    return resultado"
      ],
      "metadata": {
        "id": "sYlH-n68d-M6"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prueba de funcion de analisis de texto\n",
        "resultado_bueno = prediccion_texto(\"Este es un texto de ejemplo, el cual es muy bueno para predecir\")\n",
        "resultado_malo = prediccion_texto(\"Este es un texto de ejemplo, el cual es muy malo para predecir\")"
      ],
      "metadata": {
        "id": "u8tkCl95o7UO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#probamos resultados\n",
        "print(\"Resultado bueno \" + str(resultado_bueno), \"Resultado Malo \" + str(resultado_malo))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQwPXYAowJON",
        "outputId": "7076e0ed-6132-442b-b0c0-0d498b9c8a70"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado bueno AnalyzerOutput(output=POS, probas={POS: 0.941, NEU: 0.056, NEG: 0.003}) Resultado Malo AnalyzerOutput(output=NEG, probas={NEG: 0.970, NEU: 0.028, POS: 0.002})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cargo y proceso el modelo de audio a texto\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-tiny\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-tiny\")\n",
        "model.config.forced_decoder_ids = None\n",
        "\n",
        "#Defino funcion para transcribir el audio\n",
        "def transcribir_audio(audio_file):\n",
        "    # load audio file and extract features\n",
        "    audio, sr = librosa.load(audio_file, sr=processor.feature_extractor.sampling_rate)\n",
        "    input_features = processor(audio, sampling_rate=sr, return_tensors=\"pt\").input_features \n",
        "    \n",
        "    # generate token ids\n",
        "    predicted_ids = model.generate(input_features)\n",
        "    \n",
        "    # decode token ids to text\n",
        "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "    \n",
        "    return transcription[0]\n",
        "\n"
      ],
      "metadata": {
        "id": "Lrcxgd1kPtJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def descargar_audio(url, audio):\n",
        "    response = requests.get(url)\n",
        "\n",
        "    with open(audio, 'wb') as f:\n",
        "        f.write(response.content)"
      ],
      "metadata": {
        "id": "BgbQWZbSIZZH"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Leo archivo de audio para la prueba 1\n",
        "url = 'https://github.com/lucasnserra/Audio2Text-Sentiment-Analyst/raw/0c038956cc6eefdf69674ccdd520a368870621e0/audio.wav'\n",
        "response = requests.get(url)\n",
        "\n",
        "with open('audio.wav', 'wb') as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "audio = 'audio.wav'\n",
        "\n",
        "\n",
        "critica = transcribir_audio(audio)\n",
        "critica"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "c9RpMw5xTdgz",
        "outputId": "ec067a35-2e35-4506-9f3d-aa07bab3e040"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Clicica rápida de Wendy de Poo, Blood and Coney. No esperes una película de sentenía una buena historia, ya que no tiene absolutamente nada nuevo que contar. Sus actuaciones son malas y en sí es una película generica del género Slasher. Lo único que puede ser algo bueno es que te puedes sacar una que otra risa por algunos de sus momentos o diálogoza sordos. Calificación final, 2.5 y si quieres ver mi crítica completa, suscríbete a mi canal, sin atulado.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Leo archivo de audio para la prueba Nro 2\n",
        "url2 = 'https://github.com/lucasnserra/Audio2Text-Sentiment-Analyst/blob/main/audio2.wav?raw=true'\n",
        "response2 = requests.get(url2)\n",
        "\n",
        "with open('audio.wav', 'wb') as f:\n",
        "    f.write(response2.content)\n",
        "\n",
        "audio2 = 'audio.wav'\n",
        "critica_ = transcribir_audio(audio2)\n",
        "critica_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "qCvRkSKCcGok",
        "outputId": "3fd56664-003e-4616-8f2a-84133bf99a72"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Cripticas y en spoilers de Arman y la Vista a Cuantumania, Kang es el alma de Arman y la Vista. El conquistador por fin hace acto de presencia y quien el protagonismo que se merece, con un llor a tan mayor que parece haber nacido para este papel. La gran sorpresa para esta película ha sido modo con un personaje del que nos esperaban nada con secuencias brutalmente divertidas. Tarkomiendo que te quede esa hasta el final de la película porque cuenta con dos escenas post créditos geniales, ambas tienen repercusiones para el futuro.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Leo archivo de audio para la prueba Nro 2\n",
        "url2 = 'https://github.com/lucasnserra/Audio2Text-Sentiment-Analyst/blob/main/audio2.wav?raw=true'\n",
        "response2 = requests.get(url2)\n",
        "\n",
        "with open('audio2.wav', 'wb') as f:\n",
        "    f.write(response2.content)\n",
        "\n",
        "audio2 = 'audio2.wav'\n",
        "critica_ = transcribir_audio(audio2)\n",
        "critica_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "q5WQ25JzVCsm",
        "outputId": "8bd07c34-f762-425f-828f-cdf84275b27c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Cripticas y en spoilers de Arman y la Vista a Cuantumania, Kang es el alma de Arman y la Vista. El conquistador por fin hace acto de presencia y quien el protagonismo que se merece, con un llor a tan mayor que parece haber nacido para este papel. La gran sorpresa para esta película ha sido modo con un personaje del que nos esperaban nada con secuencias brutalmente divertidas. Tarkomiendo que te quede esa hasta el final de la película porque cuenta con dos escenas post créditos geniales, ambas tienen repercusiones para el futuro.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Leo archivo de audio para la prueba Nro 3\n",
        "url3 = 'https://github.com/lucasnserra/Audio2Text-Sentiment-Analyst/blob/main/audio3.wav?raw=true'\n",
        "response3 = requests.get(url3)\n",
        "\n",
        "with open('audio3.wav', 'wb') as f:\n",
        "    f.write(response3.content)\n",
        "\n",
        "audio3 = 'audio3.wav'\n",
        "critica_3 = transcribir_audio(audio3)\n",
        "critica_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MqU8DSyKWOGm",
        "outputId": "5ec7aac7-0238-45e0-d826-0ebbb072d31f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Venía prometiendo que va a ser la saga revolucionaria del cine y que nos iba a plantar cada para poder ver si nos hacía dónde van las películas y la verdad es que nos encontramos con un tremendo aburrimiento de trama. Mas allá del show espectacular que son. No, la pena yo. No, no. No sé si no vale la pena el show o sea si vas a ver una película yo creo que no vale la pena.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediccion = prediccion_texto(critica)\n",
        "prediccion2 = prediccion_texto(critica_)\n",
        "prediccion3 = prediccion_texto(critica_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWHkLwMiWOiJ",
        "outputId": "d524b29e-92c7-4627-c8e9-1060028da1d1"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--pysentimiento--robertuito-sentiment-analysis/snapshots/12e030859ce19539e24b486ac84ffebb9b68ecf1/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"pysentimiento/robertuito-sentiment-analysis\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEG\",\n",
            "    \"1\": \"NEU\",\n",
            "    \"2\": \"POS\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEG\": 0,\n",
            "    \"NEU\": 1,\n",
            "    \"POS\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 130,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30002\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--pysentimiento--robertuito-sentiment-analysis/snapshots/12e030859ce19539e24b486ac84ffebb9b68ecf1/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
            "\n",
            "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at pysentimiento/robertuito-sentiment-analysis.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--pysentimiento--robertuito-sentiment-analysis/snapshots/12e030859ce19539e24b486ac84ffebb9b68ecf1/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--pysentimiento--robertuito-sentiment-analysis/snapshots/12e030859ce19539e24b486ac84ffebb9b68ecf1/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--pysentimiento--robertuito-sentiment-analysis/snapshots/12e030859ce19539e24b486ac84ffebb9b68ecf1/tokenizer_config.json\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--pysentimiento--robertuito-sentiment-analysis/snapshots/12e030859ce19539e24b486ac84ffebb9b68ecf1/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"pysentimiento/robertuito-sentiment-analysis\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEG\",\n",
            "    \"1\": \"NEU\",\n",
            "    \"2\": \"POS\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEG\": 0,\n",
            "    \"NEU\": 1,\n",
            "    \"POS\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 130,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30002\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--pysentimiento--robertuito-sentiment-analysis/snapshots/12e030859ce19539e24b486ac84ffebb9b68ecf1/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
            "\n",
            "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at pysentimiento/robertuito-sentiment-analysis.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--pysentimiento--robertuito-sentiment-analysis/snapshots/12e030859ce19539e24b486ac84ffebb9b68ecf1/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--pysentimiento--robertuito-sentiment-analysis/snapshots/12e030859ce19539e24b486ac84ffebb9b68ecf1/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--pysentimiento--robertuito-sentiment-analysis/snapshots/12e030859ce19539e24b486ac84ffebb9b68ecf1/tokenizer_config.json\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--pysentimiento--robertuito-sentiment-analysis/snapshots/12e030859ce19539e24b486ac84ffebb9b68ecf1/config.json\n",
            "Model config RobertaConfig {\n",
            "  \"_name_or_path\": \"pysentimiento/robertuito-sentiment-analysis\",\n",
            "  \"architectures\": [\n",
            "    \"RobertaForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"NEG\",\n",
            "    \"1\": \"NEU\",\n",
            "    \"2\": \"POS\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"NEG\": 0,\n",
            "    \"NEU\": 1,\n",
            "    \"POS\": 2\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 130,\n",
            "  \"model_type\": \"roberta\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.26.1\",\n",
            "  \"type_vocab_size\": 1,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30002\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--pysentimiento--robertuito-sentiment-analysis/snapshots/12e030859ce19539e24b486ac84ffebb9b68ecf1/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
            "\n",
            "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at pysentimiento/robertuito-sentiment-analysis.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--pysentimiento--robertuito-sentiment-analysis/snapshots/12e030859ce19539e24b486ac84ffebb9b68ecf1/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--pysentimiento--robertuito-sentiment-analysis/snapshots/12e030859ce19539e24b486ac84ffebb9b68ecf1/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--pysentimiento--robertuito-sentiment-analysis/snapshots/12e030859ce19539e24b486ac84ffebb9b68ecf1/tokenizer_config.json\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('El resultado de la primera prediccion es ' + prediccion.output.replace('NEU', 'Neutro').replace('POS', 'Positivo').replace('NEG', 'Negativo') + ' con las siguientes probabidades ' + str(prediccion.probas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83BVLhlfro6V",
        "outputId": "d063feef-7cba-4d82-957b-52140c938283"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El resultado de la primera prediccion es Neutro con las siguientes probabidades {'NEG': 0.20106437802314758, 'NEU': 0.4933183491230011, 'POS': 0.3056173324584961}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('El resultado de la segunda prediccion es ' + prediccion2.output.replace('POS', 'Positivo').replace('NEU', 'Neutro').replace('NEG', 'Negativo') + ' con las siguientes probabidades ' + str(prediccion2.probas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdLEmFmcryhc",
        "outputId": "1f2ab419-71db-4659-98d4-237168f548b0"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El resultado de la segunda prediccion es Positivo con las siguientes probabidades {'NEG': 0.008234702050685883, 'NEU': 0.05927221477031708, 'POS': 0.9324930906295776}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('El resultado de la tercera prediccion es ' + prediccion3.output.replace('POS', 'Positivo').replace('NEU', 'Neutro').replace('NEG', 'Negativo') + ' con las siguientes probabidades ' + str(prediccion3.probas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXmjQzWMccP3",
        "outputId": "5475086b-2355-49d9-8d1b-1ecec26e751f"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El resultado de la tercera prediccion es Negativo con las siguientes probabidades {'NEG': 0.9475676417350769, 'NEU': 0.04628613591194153, 'POS': 0.00614620465785265}\n"
          ]
        }
      ]
    }
  ]
}